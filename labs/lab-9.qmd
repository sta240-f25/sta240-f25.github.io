---
title: "Lab 9"
subtitle: Due Thursday November 6 at 11:59 PM
format: html
draft: false
editor: 
  mode: source
---

An insurance company sells policies in the hope that most customers will not actually file a claim. In that case, the company keeps the premiums, and never actually pays out. Cha-ching. If on the other hand, every customer files a claim, then the company is ruined. They simply don't keep enough cash on hand to literally pay out all the customers they sell policies to.

This is obviously a risky business. The insurance company is making a bet that most of their customers won't need the policy that they bought, but there could be surprises. The company is fundamentally uncertain about how many people will file claims, and how big those claims will be. Faced with this uncertainty, they must make decisions about who to sell to, what to charge, and how much cash to keep on hand. To manage the uncertainty and make good decisions, insurance companies hire armies of *actuaries* to model the insurance market using the basic tools of probability and statistics that we are learning. Let's get a taste of that.

Imagine the Pacific All-Risk Insurance Company makes its decisions on a monthly basis. Let $N\in\mathbb{N}$ denote the number of insurance claims the company receives in a given month. Each of those claims will be for some positive dollar amount, call it $X_i>0$. So each month, customers apply for $S=X_1+X_2+...+X_N$ in reimbursement from the insurance company. The company is not sure what $N$ will be, they are not sure how big each $X_i$ will be, and so they are not sure how big the total $S$ will be. But if it gets too big, the company is finished. We shall model the number of claims $N$ and the size of each claim $X_i$ as random variables using our familiar families:

$$
\begin{aligned}
N&\sim\text{Poisson}(\lambda)
\\
X_1,\,X_2,\,X_3,\,X_4,\,...&\overset{\text{iid}}{\sim} \text{Gamma}(\alpha,\,\beta)\\
S&=\sum\limits_{i=1}^N X_i
\end{aligned}
$$

We see that $S$ is a *random sum of random variables*. Each $X_i$ is random, and the number of terms in the sum *is also* random. So randomness from both the $X_i$ and $N$ is feeding forward into the randomness in $S$, making it more challenging to model. 

In what follows, take $\lambda=100$ and $(\alpha,\,\beta)=(25,\,0.0025)$.

# Task 1

What is the probability that $N$ is strictly within one standard deviation of its mean? In other words, what is the probability that $N$ lies in the interval $(E(N)-\text{sd}(N),\,E(N)+\text{sd}(N))$. Use the appropriate `p-` function to compute this, and pay attention to the endpoints!

# Task 2

What is the probability that $N$ is at or above its mean? So, $P(N\geq E(N))$?

# Task 3

Write some `R` code that simulates `m = 5000` draws from the joint distribution of $(N,\,S)$. One way to do this is with a for loop that cycles through the following steps:

1.  Simulate $N$ and store it;
2.  Given the result of Step 1, simulate iid $X_1$, $X_2$, ..., $X_N$;
3.  Given the result of Step 2, compute $S=X_1+X_2+...+X_N$ and store it.

After the loop is complete, you should have a vector `N` storing all of the draws of $N$, and a vector `S` storing all of the draws of $S$.

# Task 4

Create a well-labeled scatterplot of the pairs $(N,\,S)$ that you just simulated.

::: callout-tip
# Adjust the point size
You might want to use the `cex` argument to the `plot` function in order to decrease the size of the points. By default `cex = 1`.
:::

# Task 5

Plot a [histogram](https://sta240-f25.github.io/explainers/histogram.html) of the draws of $S$ by themselves.

# Task 6

Use your draws of $N$ to estimate the probabilities from Tasks 1 and 2, and verify that you get estimates that are close to the actual probabilities you calculated.

# Task 7

Use the draws of $S$ to estimate the following quantities:

a. Mean of $S$;
a. Variance of $S$;
a. $P(S > 1200000)$.

# Task 8

In our setup, $N$ and $S$ are a random pair that is jointly distributed according to the following hierarchy:

$$
\begin{aligned}
N&\sim\text{Poisson}(\lambda = 100)\\
S\mid N=n &\sim \,???
\end{aligned}
$$

*Conditional* on $n$, what is the distribution of $S$? You may find results from [yesterday's lecture](https://sta240-f25.github.io/lecture-notes/sta240-notes-14-sums-and-averages.pdf) helpful.

# Task 9

Use the tower property to compute the following *marginal* expected values of $S$:

a. $E(S)$;
a. $E(S^2)$;
a. $M_S(t)=E(e^{tS})$.

::: callout-note
The marginal distribution of $S$ is not recognizable. It's some funky new thing. By deriving its MGF, you have completely characterized the distribution, but it turns out that we don't have nice clean formulas for the CDF or the PDF. Bummer! But as you saw in previous tasks, we can still *simulate* the distribution of $S$ and approximate its properties. Neat!
:::

# Task 10

Verify that the theoretical mean and variance of $S$ match the sample estimates you computed from your simulation in Task 7.

# Task 11

In our setup, we assumed that the $X_i$ were independent. 

a. What was the purely mathematical benefit of making this assumption? How did it simplify our life?
a. In the context of our application, is independence a reasonable assumption?


# Task $\infty$

Go watch [*Double Indemnity*](https://en.wikipedia.org/wiki/Double_Indemnity). It is so entertaining it will make your head spin.
